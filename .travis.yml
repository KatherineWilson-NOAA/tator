language: python
dist: focal
services:
- docker
addons:
  snaps:
  - name: helm
    confinement: classic
  - name: microk8s
    confinement: classic
    channel: 1.19
  apt:
    packages:
    - iproute2
    - net-tools
    - gzip
    - jq
before_install:
# Run local docker registry.
- docker run -d -p 5000:5000 --restart always --name registry registry:2
# Use port 5000 in values.yaml.
- sed -i "s/32000/5000/g" helm/tator/values-microk8s.yaml
# Get physical interface name.
- |
  export HOST_INTERFACE=$(ip -details -json link show | jq -r '
  .[] |
        if .linkinfo.info_kind // .link_type == "loopback" then
            empty
        else
            .ifname
        end
  ')
# Set tator host.
- export HOST_IP=$(ip addr show $(echo $HOST_INTERFACE | awk '{print $1}') | awk '$1 == "inet" {gsub(/\/.*$/, "", $2); print $2}')
# Download argo.
- curl -sLO https://github.com/argoproj/argo-workflows/releases/download/v2.12.11/argo-linux-amd64.gz && gunzip argo-linux-amd64.gz && chmod +x argo-linux-amd64 && sudo mv ./argo-linux-amd64 /usr/local/bin/argo && argo version
# Download and configure kubectl.
- curl -sLO "https://storage.googleapis.com/kubernetes-release/release/$(curl -s https://storage.googleapis.com/kubernetes-release/release/stable.txt)/bin/linux/amd64/kubectl" && chmod +x kubectl && sudo mv ./kubectl /usr/local/bin/kubectl && mkdir -p $HOME/.kube && sudo microk8s config > $HOME/.kube/config
# Label nodes.
- kubectl label nodes --all cpuWorker=yes webServer=yes dbServer=yes
install:
- echo "Host interface is $HOST_INTERFACE"
- echo "Host IP address is $HOST_IP"
#- pip install sphinx-rtd-theme recommonmark mako progressbar2 pyyaml
# Turn on microk8s add-ons.
- yes $HOST_IP-$HOST_IP | sudo microk8s enable dns metallb storage
# Install argo.
- kubectl create namespace argo && kubectl apply -n argo -f https://raw.githubusercontent.com/argoproj/argo-workflows/v2.12.11/manifests/install.yaml && kubectl apply -n argo -f argo/workflow-controller-configmap.yaml
# Configure local storage.
- sudo mkdir /media/kubernetes_share && sudo mkdir /media/kubernetes_share/elasticsearch && sudo chown -R nobody:nogroup /media/kubernetes_share && sudo chmod -R 777 /media/kubernetes_share
# Copy over values.yaml.
#- cp ./helm/tator/values-microk8s.yaml ./helm/tator/values.yaml
# Set IP address in values.yaml.
#- sed -i "s/<Insert static IP or domain>/$HOST_IP/g" helm/tator/values.yaml
#- cat helm/tator/values.yaml
# Run npm install.
#- npm install
script:
- kubectl get pods --all-namespaces
- export METALLB_POD=$(kubectl get pod -n metallb-system -l "app=metallb,component=controller" -o name | head -n 1 |sed 's/pod\///')
- kubectl describe pod -n metallb-system $METALLB_POD
- kubectl logs -n metallb-system $(kubectl get pod -n metallb-system -l "app=metallb,component=controller" -o name | head -n 1 |sed 's/pod\///')
- kubectl get pvc
- kubectl get pv
# Build the application.
#- make cluster
# Run REST tests.
#- make test
# Get gunicorn pod.
#- export GUNICORN_POD=$(kubectl get pod -l app=gunicorn -o name | head -n 1 | sed 's/pod\///')
# Create a super user with credentials travis/travis.
#- kubectl exec -it $GUNICORN_POD -- env DJANGO_SUPERUSER_PASSWORD=travis python3 manage.py createsuperuser --username travis --email no-reply@cvisionai.com --noinput
# Install tator-py wheel and run tator-py tests.
#- cd scripts/packages/tator-py && pip install dist/*.whl && pytest test --host=http://$HOST_IP --token=$(kubectl exec -it $GUNICORN_POD -- python3 manage.py shell --command="from rest_framework.authtoken.models import Token; print(Token.objects.first())")
